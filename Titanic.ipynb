{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import IPython\n",
    "from IPython import display\n",
    "import sklearn\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt # Collection of functions for scientific and publication-ready visualization\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('train.csv')\n",
    "data_val = pd.read_csv('test.csv')\n",
    "\n",
    "train_ids = data_raw['PassengerId']\n",
    "test_ids = data_val['PassengerId']\n",
    "\n",
    "data_c = data_raw.copy(deep = True)\n",
    "data_all = [data_c, data_val]\n",
    "\n",
    "print(data_c.info())\n",
    "print(data_val.info())\n",
    "data_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_c.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print(data_val.isnull().sum())\n",
    "data_c.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names and Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We check the different titles we have and group them into more general groups\n",
    "\n",
    "titles = set()\n",
    "for dataset in data_all:\n",
    "    for name in dataset['Name']:\n",
    "        titles.add(name.split(', ')[1].split('. ')[0])\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_groups = {\n",
    "    'Col':'Officer',\n",
    "    'Dona':'Royalty', \n",
    "    'Don':'Royalty',\n",
    "    'Lady':'Royalty',\n",
    "    'Mme':'Mrs',\n",
    "    'Mr':'Mr',\n",
    "    'Master':'Master',\n",
    "    'Capt':'Officer',\n",
    "    'Jonkheer':'Royalty',\n",
    "    'Miss':'Miss',\n",
    "    'Dr':'Officer',\n",
    "    'Mlle':'Miss',\n",
    "    'the Countess':'Royalty',\n",
    "    'Mrs':'Mrs',\n",
    "    'Major':'Officer',\n",
    "    'Ms':'Mrs',\n",
    "    'Rev':'Officer',\n",
    "    'Sir':'Royalty'\n",
    "}\n",
    "\n",
    "for dataset in data_all:\n",
    "    dataset['Title'] = dataset['Name'].map(lambda x : x.split(', ')[1].split('. ')[0]).map(title_groups)\n",
    "    \n",
    "#Doing a one-hot encoding of the Titles may help us depending on model. The Names column will much likely be droped in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We have 177 nulls in Age. Lets see the average Age per sex, title and class in the train dataset:\n",
    "age_medians = data_c.groupby(['Sex','Pclass','Title']).median()[['Age','Survived']].reset_index()\n",
    "age_medians\n",
    "#We can also see the difference in survival chances with these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_age_median(row):\n",
    "    return age_medians[((age_medians['Sex'] == row['Sex']) & \\\n",
    "                        (age_medians['Pclass'] == row['Pclass']) & \\\n",
    "                        (age_medians['Title'] == row['Title']))]['Age'].values[0]\n",
    "\n",
    "for dataset in data_all:\n",
    "    dataset['Age'] = dataset.apply(lambda row : get_age_median(row) if np.isnan(row['Age']) else row['Age'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "g = sns.distplot(data_c[\"Fare\"][data_c[\"Survived\"] == 0], color=\"r\")\n",
    "g = sns.distplot(data_c[\"Fare\"][data_c[\"Survived\"] == 1], color=\"b\")\n",
    "g = g.legend([\"Not Survived\",\"Survived\"])\n",
    "\n",
    "for dataset in data_all:\n",
    "    dataset['logFare'] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "g = sns.distplot(data_c[\"logFare\"][data_c[\"Survived\"] == 0], color=\"r\")\n",
    "g = sns.distplot(data_c[\"logFare\"][data_c[\"Survived\"] == 1], color=\"b\")\n",
    "g = g.legend([\"Not Survived\",\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "g = sns.distplot(data_c[\"logFare\"][data_c[\"Pclass\"] == 1], color=\"b\")\n",
    "g = sns.distplot(data_c[\"logFare\"][data_c[\"Pclass\"] == 2], color=\"orange\")\n",
    "g = sns.distplot(data_c[\"logFare\"][data_c[\"Pclass\"] == 3], color=\"g\")\n",
    "g = g.legend([\"First Class\",\"Second Class\",\"Third Class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, using a log scale for the Fare lets us visualize better how increased Fare prices lead to increased survival. This is because, as the second graph shows, people how paid more are probably high class, who we presume had an advantage on lower class people. We'll see in a bit that that's the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we fill other NAs and drop useless columns\n",
    "for dataset in data_all:\n",
    "    dataset['Embarked'].fillna('S', inplace=True)\n",
    "    \n",
    "    dataset['Fare'].fillna(dataset['Fare'].mean(), inplace=True)\n",
    "    \n",
    "    dataset['Cabin'].fillna('U',inplace=True)\n",
    "    dataset['Cabin'] = dataset['Cabin'].map(lambda x: x[0])\n",
    "    \n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    \n",
    "    dataset['IsAlone'] = 'Yes'\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 'No'\n",
    "\n",
    "    #dataset['FareBin'] = pd.qcut(dataset['Fare'], 5)\n",
    "    #dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3,figsize=(20,10))\n",
    "sns.violinplot(x=\"Sex\",y=\"Age\",hue='Survived',data=data_c,split=True,ax=ax[0,0])\n",
    "sns.barplot(x=\"Pclass\",y=\"Survived\",data=data_c,ax=ax[0,1])\n",
    "sns.barplot(x=\"Cabin\",y=\"Survived\",data=data_c,ax=ax[0,2])\n",
    "sns.barplot(x=\"Embarked\",y=\"Survived\",data=data_c,ax=ax[1,0])\n",
    "sns.barplot(x=\"Title\",y=\"Survived\",hue=\"Sex\",data=data_c,ax=ax[1,1])\n",
    "sns.barplot(x=\"FamilySize\",y=\"Survived\",hue=\"Sex\",data=data_c,ax=ax[1,2])\n",
    "fig, ax = plt.subplots(figsize=(4.65,3.5))\n",
    "sns.barplot(x=\"IsAlone\",y=\"Survived\",hue='Sex',data=data_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see some characteristics we already presumed:\n",
    "- Men have lower chances of survival then women, in general (Misters, male officers and male royalty all die far more often). Young men (20-40) are all more likely to die, while women in the same range have far better chances of survival.\n",
    "- Except for when they're young boys, as we can see the difference in the first chart, and also that the Master title (reserved for young boys) survives much more than any other male title.\n",
    "- We confirm that the higher the social status (Pclass), the higher the chances for survival. When combining this with sex, we can see that female royalty and female officers have the biggest survival chances. Male royalty also seem to have more chances than Misters, but the uncertainty is too big to draw this conclusion (as seen in the barplot).\n",
    "- The cabin doesn't seem to impact as much, except for when the person didn't have an informed cabin (U). These were much more likely to die.\n",
    "- Embarked only seems to make a difference when looking at if the person embarked at C or not.\n",
    "- Finally, men with smaller families tended to die more, while females tend to die less. It escapes me why, but perhaps, for men, the need to protect a family leads to increased survival, and, for the woman, it's because families of size above 4 seem to be maily women, putting more weight to their total death toll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in data_all:\n",
    "    dataset['Sex'] = dataset['Sex'].map({'male' : 1, 'female' : 0, 1:1, 0:0})\n",
    "    \n",
    "    dataset['IsAlone'] = dataset['IsAlone'].map({'Yes' : 1, 'No' : 0, 1:1, 0:0})\n",
    "    \n",
    "    #dataset['Embarked'] = dataset['Embarked'].map({'S' : 0, 'C' : 1, 'Q' :2})\n",
    "    \n",
    "    #dataset['Cabin'] = dataset['Cabin'].map({'U':0,'C':1,'E':2,'G':3,'D':4,'A':5,'B':6,'F':7,'T':8})\n",
    "    \n",
    "    #dataset['Title'] = dataset['Title'].map({'Mr':0,'Mrs':1,'Miss':2,'Master':3,'Royalty':4,'Officer':5})\n",
    "    \n",
    "    drop_column = ['PassengerId','Name', 'Ticket','Fare']\n",
    "    dataset.drop(drop_column, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def categorize_row(dataset,row_name):\n",
    "    dummies = pd.get_dummies(dataset[row_name], prefix=row_name)\n",
    "    dataset = pd.concat([dataset, dummies], axis=1)\n",
    "    dataset.drop(row_name, axis=1, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "data_c = categorize_row(data_c,'Embarked')\n",
    "data_c = categorize_row(data_c,'Cabin')\n",
    "data_c = categorize_row(data_c,'Title')\n",
    "\n",
    "data_val = categorize_row(data_val,'Embarked')\n",
    "data_val = categorize_row(data_val,'Cabin')\n",
    "data_val = categorize_row(data_val,'Title')\n",
    "\n",
    "data_c.drop('Cabin_T', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data_c.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print(data_val.isnull().sum())\n",
    "data_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold as SKF\n",
    "from sklearn.model_selection import cross_val_score as cv_score\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.mixture import BayesianGaussianMixture as BGMM\n",
    "from sklearn.model_selection import GridSearchCV as GridS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data_c['Survived'].values\n",
    "X = data_c.drop('Survived',axis=1).values\n",
    "y.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RFC_parameter_grid = {'max_depth' : [4, 6, 8, 10],\n",
    "                 'n_estimators': [100, 50, 10],\n",
    "                 'max_features' : ['sqrt', 'auto', 'log2'],\n",
    "                 'min_samples_split': [2, 3, 10],\n",
    "                 'min_samples_leaf': [1, 3, 10],\n",
    "                 'bootstrap': [True, False],}\n",
    "\n",
    "RFC_grid = GridS(RFC(),\n",
    "                    scoring='accuracy',\n",
    "                    param_grid=RFC_parameter_grid,\n",
    "                    cv=SKF(n_splits=5),\n",
    "                    verbose=1)\n",
    "\n",
    "RFC_grid.fit(X, y)\n",
    "\n",
    "RFC_params = RFC_grid.best_params_\n",
    "\n",
    "print('Best score: {}'.format(RFC_grid.best_score_))\n",
    "print('Best parameters: {}'.format(RFC_params))\n",
    "\n",
    "pred = RFC_grid.predict(data_val.values).astype(int)\n",
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = test_ids.values\n",
    "output['Survived'] = pred\n",
    "output[['PassengerId','Survived']].to_csv('./RFC_prediction.csv', index=False)\n",
    "\n",
    "#max score on kaggle so far: {'bootstrap': True, 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RFC_clf = RFC(**RFC_params)\n",
    "RFC_clf.fit(X,y)\n",
    "importances = pd.DataFrame()\n",
    "importances['Feature'] = data_val.columns.tolist()\n",
    "importances['Importance'] = RFC_clf.feature_importances_.tolist()\n",
    "importances.sort_values(by='Importance',inplace=True,ascending=False)\n",
    "importances.reset_index(drop=True,inplace=True)\n",
    "importances['Accumulated Importance'] = [np.sum(importances['Importance'].tolist()[:i+1]) for (i,n) in enumerate(importances['Importance'].tolist())]\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected = importances.iloc[0:15]['Feature'].values\n",
    "X_s = data_c[selected].values\n",
    "y.shape,X_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RFC_parameter_grid = {'max_depth' : [4, 6, 8, 10],\n",
    "                 'n_estimators': [100, 50, 10],\n",
    "                 'max_features' : ['sqrt', 'auto', 'log2'],\n",
    "                 'min_samples_split': [2, 3, 10],\n",
    "                 'min_samples_leaf': [1, 3, 10],\n",
    "                 'bootstrap': [True, False],}\n",
    "\n",
    "RFC_grid = GridS(RFC(),\n",
    "                    scoring='accuracy',\n",
    "                    param_grid=RFC_parameter_grid,\n",
    "                    cv=SKF(n_splits=5),\n",
    "                    verbose=1)\n",
    "\n",
    "RFC_grid.fit(X_s, y)\n",
    "\n",
    "RFC_params = RFC_grid.best_params_\n",
    "\n",
    "print('Best score: {}'.format(RFC_grid.best_score_))\n",
    "print('Best parameters: {}'.format(RFC_params))\n",
    "\n",
    "pred = RFC_grid.predict(data_val.values).astype(int)\n",
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = test_ids.values\n",
    "output['Survived'] = pred\n",
    "output[['PassengerId','Survived']].to_csv('./RFC_prediction.csv', index=False)\n",
    "\n",
    "#max score on kaggle so far: {'bootstrap': True, 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BGMM_parameter_grid = {'n_components':[10,20,40,80,100],\n",
    "                      'covariance_type':['full','tied','diag','spherical'],\n",
    "                      'max_iter':[10,50,100,200],\n",
    "                      }\n",
    "\n",
    "BGMM_grid = GridS(BGMM(),\n",
    "                    scoring='accuracy',\n",
    "                    param_grid=BGMM_parameter_grid,\n",
    "                    cv=SKF(n_splits=5),\n",
    "                    verbose=1)\n",
    "\n",
    "BGMM_grid.fit(X, y)\n",
    "\n",
    "BGMM_params = BGMM_grid.best_params_\n",
    "\n",
    "print('Best score: {}'.format(BGMM_grid.best_score_))\n",
    "print('Best parameters: {}'.format(BGMM_params))\n",
    "\n",
    "BGMM_model = BGMM(**BGMM_params)\n",
    "BGMM_model.fit(X,y)\n",
    "\n",
    "pred = BGMM_grid.predict(data_val.values).astype(int)\n",
    "output = pd.DataFrame()\n",
    "output['PassengerId'] = test_ids.values\n",
    "output['Survived'] = pred\n",
    "output[['PassengerId','Survived']].to_csv('./GMM_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Initialize bagging classifier.'''\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagg = BaggingClassifier(base_estimator = rf, verbose = 0, n_jobs = -1, random_state = seed)\n",
    "'''We use rf as the base estimator for bagging technique.'''\n",
    "print('Fitting Bagging Ensemble...')\n",
    "display(bagg.fit(X_train, y_train))\n",
    "print('Done.')\n",
    "\n",
    "'''Bagging cross validation score.'''\n",
    "print('\\nComputing Bagging X Val Score..')\n",
    "bagg_x_val_score = cross_val_score(bagg, X_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "bagg_x_val_score = np.round(bagg_x_val_score.mean()*100, 2)\n",
    "print('Done.')\n",
    "\n",
    "'''Compare bagging ensemble score with best base models scores.'''\n",
    "bagg_vs_base_score = pd.DataFrame({'Bagging_vs_base_score(%)': [bagg_x_val_score, rf_best_score, gbc_best_score, dt_best_score, knn_best_score, lr_best_score]})\n",
    "'''So basically we're comparing bagging x_val_score with base models's tunned score.'''\n",
    "bagg_vs_base_score.index = ['Bagg', 'RF', 'GBC', 'DT', 'KNN', 'LR']\n",
    "bold('**Bagging vs Base Models Scores:**')\n",
    "display(bagg_vs_base_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
